{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORaeexr7umRY++26CpvFZ0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leakysam/Soccer-Scraper/blob/League-%26-HT-score/Scrapper_Branch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bf27ZmMlcO3K"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime, timedelta\n",
        "import re\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Function to format date as needed in the URL\n",
        "def format_date_url(date):\n",
        "    return date.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "# Specify the starting date\n",
        "start_date = datetime(2024, 1, 1)\n",
        "\n",
        "# Number of days to scrape\n",
        "num_days = 21\n",
        "\n",
        "# Create an empty list to store the extracted data\n",
        "all_data = []\n",
        "\n",
        "# Iterate over the specified number of days\n",
        "for day in range(num_days):\n",
        "    # Calculate the current date\n",
        "    current_date = start_date + timedelta(days=day)\n",
        "\n",
        "    # Construct the URL with the dynamic date\n",
        "    url = f\"https://www.forebet.com/en/football-predictions/under-over-25-goals/{format_date_url(current_date)}\"\n",
        "\n",
        "    # Set the user-agent header\n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
        "    }\n",
        "\n",
        "    # Send an HTTP request to the URL with the specified headers\n",
        "    response = requests.get(url, headers=headers)\n",
        "\n",
        "    # Check if the request was successful (status code 200)\n",
        "    if response.status_code == 200:\n",
        "        try:\n",
        "            # Parse the HTML content of the page\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "            # Extract data from specific HTML elements\n",
        "            team_divs = soup.find_all('div', class_='tnms')\n",
        "            avg_goals_divs = soup.find_all('div', class_='avg_sc tabonly')\n",
        "\n",
        "            # Extract coefficients from both div and span structures\n",
        "            coef_values = []\n",
        "            coef_divs = soup.find_all('div', class_='bigOnly prmod')\n",
        "            for div in coef_divs:\n",
        "                span = div.find('span', class_='lscrsp')\n",
        "                coef = div.find('span', class_='lscrsp') or div.find('span')\n",
        "                match = re.search(r'\\d+\\.\\d+', coef.get_text(strip=True)) if coef else None\n",
        "                coef_values.append(match.group() if match else 'N/A')\n",
        "\n",
        "            # Extract score values from both div and span structures\n",
        "            score_values = []\n",
        "            score_divs = soup.find_all('div', class_='lscr_td')\n",
        "            for div in score_divs:\n",
        "                b = div.find('b', class_='l_scr')\n",
        "                score_text = b.get_text(strip=True) if b else 'N/A'\n",
        "                score_values.append(score_text)\n",
        "\n",
        "            # Extract ht_scr values from both div and span structures\n",
        "            ht_values = []\n",
        "            ht_divs = soup.find_all('div', class_='lscr_td')\n",
        "            for div in ht_divs:\n",
        "                ht_span = div.find('span', class_='ht_scr')\n",
        "                ht_text = ht_span.get_text(strip=True) if ht_span else 'N/A'\n",
        "                ht_values.append(ht_text)\n",
        "\n",
        "            # Extract league_country values from both div and span structures\n",
        "            league_country_values = []\n",
        "            league_country_divs = soup.find_all('div', class_='shortagDiv tghov')\n",
        "            for div in league_country_divs:\n",
        "                short_tag_span = div.find('span', class_='shortTag')\n",
        "                short_tag_text = short_tag_span.get_text(strip=True) if short_tag_span else 'N/A'\n",
        "                league_country_values.append(short_tag_text)\n",
        "\n",
        "            # Create lists to store the extracted data\n",
        "            teams = [div.get_text(strip=True) for div in team_divs]\n",
        "            avg_goals = [div.get_text(strip=True) for div in avg_goals_divs]\n",
        "\n",
        "            # Determine the minimum length of all lists\n",
        "            min_length = min(len(teams), len(avg_goals), len(coef_values), len(score_values), len(ht_values), len(league_country_values))\n",
        "\n",
        "            # Append the extracted data to the list\n",
        "            for i in range(min_length):\n",
        "                data = {\n",
        "                    'Date': format_date_url(current_date),\n",
        "                    'Team': teams[i],\n",
        "                    'Avg. Goals': avg_goals[i],\n",
        "                    'Coef. Value': coef_values[i],\n",
        "                    'Score': score_values[i],\n",
        "                    'HT Score': ht_values[i],\n",
        "                    'League_Country': league_country_values[i]  # Add the new column\n",
        "                }\n",
        "                all_data.append(data)\n",
        "\n",
        "        except AttributeError as e:\n",
        "            print(f\"Error extracting data: {e}\")\n",
        "    else:\n",
        "        print(f\"Error: Unable to fetch data. Status code: {response.status_code}\")\n",
        "\n",
        "# Convert the list of dictionaries to a Pandas DataFrame\n",
        "df = pd.DataFrame(all_data)\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_file = 'output_data.xlsx'\n",
        "df.to_excel(output_file, index=False)\n",
        "\n",
        "print(f\"Data has been successfully scraped and stored in '{output_file}'\")\n"
      ]
    }
  ]
}